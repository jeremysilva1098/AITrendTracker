---
layout: default
---
<style>
    body {
        zoom: 125%; /* Adjust the zoom level as per your requirement */
    }
</style>
<!DOCTYPE html>
<html>
<head>
<title>Top Research Articles of the Week</title>
</head>
<body>
<h1>Top Research Articles of the Week</h1>

<h2>Title: How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis</h2>
<h3>Summary:</h3>
<ul>
  <li>The researchers developed NEGOTIATION ARENA, an open-source platform for evaluating the negotiation abilities of large language models (LLMs).</li>
  <li>LLM agents can significantly improve their negotiation outcomes by employing certain behavioral tactics, such as pretending to be desperate or using insults.</li>
  <li>The order in which an agent goes and its role in the negotiation have a significant impact on the outcome.</li>
  <li>LLM agents exhibit biases and limitations, including anchoring and numerosity biases.</li>
  <li>Understanding these irrational behaviors and vulnerabilities is important for improving the reliability of LLM agents.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.05863v1">Link</a>

<h2>Title: Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS</h2>
<h3>Summary:</h3>
<ul>
  <li>Existing large language models (LLMs) for Verilog RTL code generation struggle with compilation failures and sub-optimal power, performance, and area (PPA) efficiency.</li>
  <li>The paper proposes an automated technique that combines Monte Carlo tree-search (MCTS) with LLMs to generate compilable, functionally correct, and PPA-optimized Verilog code.</li>
  <li>The technique consistently generates functionally correct code and effectively addresses the PPA-unawareness drawback of naive LLMs.</li>
  <li>For the largest design (16-bit adder), the technique achieves a 31.8% improvement in the area-delay product.</li>
  <li>The technique can be further improved by fine-tuning the LLM parameters and striking a balance between exploration and exploitation.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.03289v1">Link</a>

<h2>Title: A call for embodied AI</h2>
<h3>Summary:</h3>
<ul>
  <li>Embodied AI (E-AI) is proposed as the next step in the pursuit of Artificial General Intelligence (AGI), distinguishing itself from current AI advancements.</li>
  <li>E-AI emphasizes perception, action, memory, and learning as essential components of an embodied agent and aligns with the active inference principle.</li>
  <li>Large Language Models (LLMs) like GPT-4 and Gemini have made significant progress in AI, but they lack the ability to evolve with time and experience.</li>
  <li>E-AI agents should be capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities in real-world environments.</li>
  <li>Challenges in E-AI research include formulating a new AI learning theory, innovation in advanced hardware, managing noise and uncertainty, simulators, and enhancing AI-human communication.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.03824v1">Link</a>

<h2>Title: Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases</h2>
<h3>Summary:</h3>
<ul>
  <li>Prompt engineering is crucial for optimizing the performance of Large Language Models (LLMs) on various tasks.</li>
  <li>A new method called Intent-based Prompt Calibration (IPC) is introduced, which uses a calibration process to refine the prompt based on user intent.</li>
  <li>IPC generates synthetic boundary cases and optimizes the prompt according to the generated dataset, outperforming state-of-the-art methods with limited annotated samples.</li>
  <li>IPC can be applied to tasks such as moderation and generation, and is modular and adaptable to different use cases.</li>
  <li>The system incorporates meta-prompts for sample generation, prompt analysis, and prompt generation, improving the effectiveness of the optimization process.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.03099v1">Link</a>

<h2>Title: C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models</h2>
<h3>Summary:</h3>
<ul>
  <li>This paper presents C-RAG, a framework that provides certified generation risks for retrieval-augmented language models (RAG).</li>
  <li>C-RAG provides conformal risk analysis for RAG models and certifies an upper confidence bound of generation risks.</li>
  <li>Theoretical analysis shows that RAG models achieve lower conformal generation risks compared to single language models without retrieval.</li>
  <li>Empirical results demonstrate the soundness and tightness of conformal generation risk guarantees across different datasets and retrieval models.</li>
  <li>C-RAG allows for adjusting RAG configurations to control generation risks, and larger numbers of retrieved examples lead to lower risks.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.03181v1">Link</a>

<h2>Title: KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models</h2>
<h3>Summary:</h3>
<ul>
  <li>The paper introduces a method called KS-Lottery for identifying winning tickets in fine-tuned large language models (LLMs).</li>
  <li>KS-Lottery uses the Kolmogorov-Smirnov Test to analyze the distribution shift of parameters before and after fine-tuning.</li>
  <li>The method focuses on finding winning tickets in the embedding layer of LLMs and demonstrates that fine-tuning only a small subset of token embeddings can achieve comparable performance to full fine-tuning.</li>
  <li>The paper provides theoretical evidence that KS-Lottery can find certified winning tickets and shows empirical results supporting its effectiveness.</li>
  <li>KS-Lottery is shown to be more efficient than other parameter-efficient tuning algorithms while achieving similar performance levels.</li>
</ul>
<a href="http://arxiv.org/pdf/2402.02801v1">Link</a>

</body>
</html>